{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6dc9MaU-iYy"
      },
      "source": [
        "# Face Recognition\n",
        "\n",
        "Muchas de las ideas presentadas aquí son de [FaceNet](https://arxiv.org/pdf/1503.03832.pdf), [DeepFace](https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf). \n",
        "\n",
        "Los problemas de reconocimiento facial comúnmente se dividen en dos categorías:\n",
        "\n",
        "- **Face verification** - \"¿Es esta la persona reclamada?\". Por ejemplo, en algunos aeropuertos, puede pasar por la aduana dejando que un sistema escanee su pasaporte y luego verifique que usted (la persona que lleva el pasaporte) es la persona correcta. Un teléfono móvil que se desbloquea usando tu rostro también usa verificación facial. Este es un problema de correspondencia 1:1.\n",
        "- **Face Recognition** - \"¿Quién es esta persona?\". Por ejemplo, se muestra un [video de reconocimiento facial](https://www.youtube.com/watch?v=wr4rx0Spihs) de empleados de Baidu que ingresaban a la oficina sin necesidad de identificarse. Este es un problema de coincidencia 1:K.\n",
        "\n",
        "FaceNet aprende una red neuronal que codifica una imagen de rostro en un vector de 128 números. Al comparar dos de estos vectores, puede determinar si dos imágenes son de la misma persona.\n",
        "    \n",
        "**usted:**\n",
        "- Implementará la triplet loss function\n",
        "- Usa un modelo previamente entrenado para mapear imágenes de rostros en codificaciones de 128 dimensiones\n",
        "- Use estas codificaciones para realizar la verificación facial y el reconocimiento facial\n",
        "\n",
        "#### Primera notación de canales\n",
        "\n",
        "* Usaremos un modelo previamente entrenado que representa las activaciones de ConvNet usando una convención de **\"channels-first\"**, a diferencia de la convención de \"channels last\", un lote de imágenes tendrá la forma $(m, n_C, n_H, n_W)$ en lugar de $(m, n_H, n_W, n_C)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **!! IMPORTANTE !!**\n",
        "\n",
        "**<font color='red'>Debido a que el modelo es creado en un entorno con GPU, puede causar problemas a la hora de ejecutarlo en CPU</font>**\n",
        "\n",
        "```python \n",
        "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", FRmodel)\n",
        "\n",
        "  File \"C:\\Users\\sandr\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\layers\\pooling\\base_pooling2d.py\", line 84, in call\n",
        "      outputs = self.pool_function(\n",
        "Node: 'FaceRecoModel/max_pooling2d/MaxPool'\n",
        "Default MaxPoolingOp only supports NHWC on device type CPU\n",
        "\t [[{{node FaceRecoModel/max_pooling2d/MaxPool}}]] [Op:__inference_predict_function_3796]\n",
        "\n",
        "```\n",
        "\n",
        "**<font color='green'>En el caso de no contar con GPU, puede abrir este notebook en Google Colab, cambiar el tipo de ejecución de GPU, y luego subir los archivos</font>** `fr_utils.py`, `inception_block_v2.py` y los archivos a descargar que son [images.zip](https://drive.google.com/file/d/1u19mxnToRuOtPhLscBDJQp-POmfiCScw/view?usp=share_link) y [weights.zip](https://drive.google.com/file/d/1BBytSkyl2ckdiTWChO0uJf5gLM0ox5Ny/view?usp=share_link)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejecutar las siguientes celdas, una vez que tienes los archivos .zip subidos a Colab, de tal manera puedas descomprimir las carpetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zmHfx0yV_IF6"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/images.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b18THbPI_H6A",
        "outputId": "19c26b62-913c-4ac2-d1b9-7d430e98f519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "replace /content/inception_blocks_v2.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip -q /content/weights.zip -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Estructura de carpetas y archivos**\n",
        "\n",
        "```\n",
        "images <- imagenes de miembros de la compañía\n",
        "weights <- Pesos pre-entrenados del modelo inception_v2 ya definido (archivos.csv)\n",
        "└─── bn1_b.csv\n",
        "     ...\n",
        "fr_utils.py <- Funciones para la asignación de pesos a las capas del modelo y para las predicciones\n",
        "inception_blocks_v2.py <- Arquitectura del modelo inception_v2 utilizado\n",
        "face_recognition.ipynb <- Descripción de todo el proceso llevado en el reconocimiento facial\n",
        "...\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oecprmIx-iY3"
      },
      "source": [
        "## 1. Importamos Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u92KePSm-iY4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, BatchNormalization, MaxPool2D, AveragePooling2D, Dense, Flatten, Lambda\n",
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "from fr_utils import *\n",
        "from inception_blocks_v2 import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSC1e-Od-iY6"
      },
      "source": [
        "## 2. Naive Face Verification\n",
        "\n",
        "En Face Verification, te dan dos imágenes y tienes que determinar si son de la misma persona. La forma más sencilla de hacer esto es comparar las dos imágenes píxel por píxel. Si la distancia entre las imágenes sin procesar es menor que un umbral elegido, ¡puede ser la misma persona!\n",
        "\n",
        "<div align='center'>\n",
        "<img src=\"images/pixel_comparison.png\" style=\"width:410px;height:180px;\">\n",
        "</div>\n",
        "<caption><center> <u> <font color='blue'> Figura 1 </u></center></caption>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziDPQUrL-iY6"
      },
      "source": [
        "* Por supuesto, este algoritmo funciona muy mal, ya que los valores de los píxeles cambian drásticamente debido a las variaciones en la iluminación, la orientación del rostro de la persona, incluso cambios menores en la posición de la cabeza, etc.\n",
        "* Verá que en lugar de usar la imagen sin procesar, puede aprender una codificación, $f(img)$.\n",
        "* Al usar una codificación para cada imagen, una comparación de elementos produce un juicio más preciso sobre si dos imágenes son de la misma persona."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM2mMZhS-iY7"
      },
      "source": [
        "## 3. Codificación de imágenes de rostros en un vector de 128 dimensiones\n",
        "\n",
        "### 3.1. Uso de ConvNet para calcular codificaciones\n",
        "\n",
        "El modelo FaceNet requiere muchos datos y mucho tiempo para entrenar. Entonces, siguiendo la práctica común en el aprendizaje profundo aplicado, carguemos pesos que alguien más ya ha entrenado. La arquitectura de la red sigue el modelo Inception de [Szegedy *et al.*](https://arxiv.org/abs/1409.4842). Hemos proporcionado una implementación de red inicial. Puede buscar en el archivo `inception_blocks_v2.py` para ver cómo se implementa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNQXwogH-iY8"
      },
      "source": [
        "Las cosas clave que necesita saber son:\n",
        "\n",
        "- Esta red utiliza imágenes RGB de 96x96 dimensiones como entrada. Específicamente, ingresa una imagen facial (o lote de $m$ imágenes faciales) como un tensor de forma $(m, n_C, n_H, n_W) = (m, 3, 96, 96)$\n",
        "- Produce una matriz de forma $(m, 128)$ que codifica cada imagen facial de entrada en un vector de 128 dimensiones\n",
        "\n",
        "Ejecute la celda a continuación para crear el modelo para imágenes de rostros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IHhBK4sf-iY8"
      },
      "outputs": [],
      "source": [
        "FRmodel = faceRecoModel(input_shape = (3,96,96))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rs-ajKK-iY9",
        "outputId": "111176ac-a64e-45ac-99b1-0581a8906216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Params: 3743280\n"
          ]
        }
      ],
      "source": [
        "print(\"Total Params:\", FRmodel.count_params())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbE2IMd6-iY-"
      },
      "source": [
        "Al usar una capa totalmente conectada de 128 neuronas como su última capa, el modelo garantiza que la salida sea un vector de codificación de tamaño 128. Luego, usa las codificaciones para comparar dos imágenes de rostros de la siguiente manera:\n",
        "\n",
        "<div align='center'>\n",
        "<img src=\"images/distance_kiank.png\" style=\"width:680px;height:250px;\">\n",
        "<div>\n",
        "<caption><center> <u> <font color='blue'> Figura 2: <br> </u> <font color='blue'> Al calcular la distancia entre dos codificaciones y el umbral, usted puede determinar si las dos imágenes representan a la misma persona</center></caption>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciPovOpO-iY-"
      },
      "source": [
        "Entonces, una codificación es buena si:\n",
        "- Las codificaciones de dos imágenes de la misma persona son bastante similares entre sí.\n",
        "- Las codificaciones de dos imágenes de diferentes personas son muy diferentes.\n",
        "\n",
        "La triplet loss function formaliza esto y trata de \"empujar\" las codificaciones de dos imágenes de la misma persona (Anchor y Positive) más juntas, mientras \"jala\" las codificaciones de dos imágenes de personas diferentes (Anchor, Negative) más separadas.\n",
        "\n",
        "<div align = 'center'>\n",
        "<img src=\"images/triplet_comparison.png\" style=\"width:300px;height:170px;\">\n",
        "</div>\n",
        "<br>\n",
        "<caption><center> <u> <font color='blue'> Figure 3: <br> </u> <font color='blue'> En la siguiente parte, llamaremos a las imágenes de izquierda a derecha: anchor (A), positive (P), negative (N) </center></caption>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKQi3J8p-iY_"
      },
      "source": [
        "### 3.2. Triplet loss function\n",
        "\n",
        "Para una imagen $x$, denotamos su codificación $f(x)$, donde $f$ es la función calculada por la red neuronal.\n",
        "\n",
        "<img src=\"images/f_x.png\" style=\"width:400px;height:180px;\">\n",
        "\n",
        "El entrenamiento utilizará tripletas de imágenes $(A, P, N)$:\n",
        "\n",
        "- A es una imagen de \"ancla\": una imagen de una persona.\n",
        "- P es una imagen \"Positiva\": una imagen de la misma persona que la imagen del Ancla.\n",
        "- N es una imagen \"negativa\": una imagen de una persona diferente a la imagen de anclaje.\n",
        "\n",
        "**Estos trillizos se seleccionan de nuestro conjunto de datos de entrenamiento**. Escribiremos $(A^{(i)}, P^{(i)}, N^{(i)})$ para indicar el ejemplo de entrenamiento $i$-ésimo.\n",
        "\n",
        "Le gustaría asegurarse de que una imagen $A^{(i)}$ de un individuo esté más cerca de la $P^{(i)}$ positiva que de la imagen negativa $N^{(i)}$ ) por al menos un margen $\\alpha$:\n",
        "\n",
        "$$\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 + \\alpha < \\mid \\mid f(A^{(i)} ) - f(N^{(i)}) \\mid \\mid_2^2$$\n",
        "\n",
        "Por lo tanto, le gustaría minimizar el siguiente \"triplet cost\":\n",
        "\n",
        "$$\\mathcal{J} = \\sum^{m}_{i=1} \\large[ \\small \\underbrace{\\mid \\mid f(A^{(i)}) - f(P^{(i )}) \\mid \\mid_2^2}_\\text{(1)} - \\underbrace{\\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2}_\\text{(2)} + \\alpha \\large ] \\small_+ \\tag{3}$$\n",
        "\n",
        "Aquí, estamos usando la notación \"$[z]_+$\" para denotar $max(z,0)$.\n",
        "\n",
        "Notas:\n",
        "- El término (1) es la distancia al cuadrado entre el ancla \"A\" y el positivo \"P\" para un triplete dado; quieres que esto sea pequeño.\n",
        "- El término (2) es la distancia al cuadrado entre el ancla \"A\" y la \"N\" negativa para un triplete dado, desea que sea relativamente grande. Tiene un signo menos que lo precede porque minimizar el negativo del término es lo mismo que maximizar ese término.\n",
        "- $\\alpha$ se llama margen. Es un hiperparámetro que selecciona manualmente. Usaremos $\\alpha = 0.2$.\n",
        "\n",
        "La mayoría de las implementaciones también reescalan los vectores de codificación para tener una norma L2 igual a uno (es decir, $\\mid \\mid f(img)\\mid \\mid_2$=1); no tendrás que preocuparte por eso en esta tarea.\n",
        "\n",
        "**Ejercicio**: Implemente la pérdida de triplete como se define en la fórmula (3). Aquí están los 4 pasos:\n",
        "1. Calcule la distancia entre las codificaciones de \"ancla\" y \"positivo\": $\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2$\n",
        "2. Calcule la distancia entre las codificaciones de \"ancla\" y \"negativo\": $\\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2$\n",
        "3. Calcule la fórmula por ejemplo de entrenamiento: $ \\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 - \\mid \\mid f(A^ {(i)}) - f(N^{(i)}) \\mid \\mid_2^2 + \\alpha$\n",
        "4. Calcule la fórmula completa tomando el máximo con cero y sumando los ejemplos de entrenamiento:\n",
        "$$\\mathcal{J} = \\sum^{m}_{i=1} \\large[ \\small \\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 - \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2+ \\alpha \\large ] \\small_+ \\tag{ 3}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cqJexMfl-iZA"
      },
      "outputs": [],
      "source": [
        "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
        "    \"\"\"\n",
        "        Implementación de triplet loss según lo definido por la fórmula (3)\n",
        "\n",
        "        Argumentos:\n",
        "        y_true: Etiquetas verdaderas, requeridas cuando define una pérdida en Keras, no la necesita en esta función\n",
        "        y_pred: Lista que contiene 3 objetos:\n",
        "            * anchor: las codificaciones para las imágenes ancla de forma (None, 128)\n",
        "            * positive: las codificaciones para las imágenes positivas de forma (None, 128)\n",
        "            * negative: las codificaciones para las imágenes negativas de forma (None, 128)\n",
        "    \"\"\"\n",
        "\n",
        "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
        "\n",
        "    # step1\n",
        "    post_dist = tf.reduce_sum(tf.square(anchor - positive), axis = -1)\n",
        "    # step2\n",
        "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis = -1)\n",
        "    # step3\n",
        "    basic_loss = post_dist - neg_dist + alpha\n",
        "\n",
        "    # step4\n",
        "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmxNEP7D-iZA",
        "outputId": "d90538c4-1849-4b00-d8c7-746a02d433c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss =  527.2598\n"
          ]
        }
      ],
      "source": [
        "tf.random.set_seed(1)\n",
        "y_true = (None, None, None)\n",
        "y_pred = (tf.random.normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
        "          tf.random.normal([3, 128], mean=1, stddev=1, seed = 1),\n",
        "          tf.random.normal([3, 128], mean=3, stddev=4, seed = 1))\n",
        "loss = triplet_loss(y_true, y_pred)\n",
        "print(\"loss = \", loss.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMkxzIxb-iZB"
      },
      "source": [
        "### 3.3 - Cargando el modelo pre-entrenado\n",
        "\n",
        "FaceNet se entrena minimizando la pérdida de triplete. Pero dado que el entrenamiento requiere muchos datos y muchos cálculos, no lo entrenaremos desde cero aquí. En su lugar, cargamos un modelo previamente entrenado. Cargue un modelo usando la siguiente celda; esto puede tardar un par de minutos en ejecutarse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D1jNoGQY-iZB"
      },
      "outputs": [],
      "source": [
        "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
        "load_weights_from_FaceNet(FRmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c92n-wQQ-iZB"
      },
      "source": [
        "Aquí hay algunos ejemplos de distancias entre las codificaciones entre tres individuos:\n",
        "<div align='center'>\n",
        "<img src=\"images/distance_matrix.png\" style=\"width:380px;height:200px;\">\n",
        "</div>\n",
        "<br>\n",
        "<caption><center> <u> <font color='blue'> Figura 4:</u> <br>  <font color='blue'> Ejemplo de outputs de distancia entre codificaciones de tres individuos </center></caption>\n",
        "\n",
        "¡Usemos ahora este modelo para realizar la verificación facial y el reconocimiento facial!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0M-7C6YH-iZC"
      },
      "source": [
        "Está construyendo un sistema para un edificio de oficinas en el que al administrador del edificio le gustaría ofrecer reconocimiento facial para permitir que los empleados ingresen al edificio.\n",
        "\n",
        "Le gustaría crear un sistema de **verificación facial** que dé acceso a la lista de personas que viven o trabajan allí. Para ser admitido, cada persona debe deslizar una tarjeta de identificación (tarjeta de identificación) para identificarse en la entrada. Luego, el sistema de reconocimiento facial verifica que son quienes dicen ser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBLtHxgn-iZC",
        "outputId": "1947b536-e38e-40f3-9e0a-0de2f1d67c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"FaceRecoModel\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 3, 96, 96)]  0           []                               \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 3, 102, 102)  0          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)                 (None, 64, 48, 48)   9472        ['zero_padding2d[0][0]']         \n",
            "                                                                                                  \n",
            " bn1 (BatchNormalization)       (None, 64, 48, 48)   256         ['conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 64, 48, 48)   0           ['bn1[0][0]']                    \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 64, 50, 50)  0           ['activation[0][0]']             \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 64, 24, 24)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2 (Conv2D)                 (None, 64, 24, 24)   4160        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " bn2 (BatchNormalization)       (None, 64, 24, 24)   256         ['conv2[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 64, 24, 24)   0           ['bn2[0][0]']                    \n",
            "                                                                                                  \n",
            " zero_padding2d_2 (ZeroPadding2  (None, 64, 26, 26)  0           ['activation_1[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3 (Conv2D)                 (None, 192, 24, 24)  110784      ['zero_padding2d_2[0][0]']       \n",
            "                                                                                                  \n",
            " bn3 (BatchNormalization)       (None, 192, 24, 24)  768         ['conv3[0][0]']                  \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 192, 24, 24)  0           ['bn3[0][0]']                    \n",
            "                                                                                                  \n",
            " zero_padding2d_3 (ZeroPadding2  (None, 192, 26, 26)  0          ['activation_2[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 192, 12, 12)  0          ['zero_padding2d_3[0][0]']       \n",
            "                                                                                                  \n",
            " inception_3a_3x3_conv1 (Conv2D  (None, 96, 12, 12)  18528       ['max_pooling2d_1[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3a_5x5_conv1 (Conv2D  (None, 16, 12, 12)  3088        ['max_pooling2d_1[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3a_3x3_bn1 (BatchNor  (None, 96, 12, 12)  384         ['inception_3a_3x3_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_3a_5x5_bn1 (BatchNor  (None, 16, 12, 12)  64          ['inception_3a_5x5_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 96, 12, 12)   0           ['inception_3a_3x3_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 12, 12)   0           ['inception_3a_5x5_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 192, 5, 5)   0           ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " zero_padding2d_4 (ZeroPadding2  (None, 96, 14, 14)  0           ['activation_3[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " zero_padding2d_5 (ZeroPadding2  (None, 16, 16, 16)  0           ['activation_5[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " inception_3a_pool_conv (Conv2D  (None, 32, 5, 5)    6176        ['max_pooling2d_2[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3a_3x3_conv2 (Conv2D  (None, 128, 12, 12)  110720     ['zero_padding2d_4[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3a_5x5_conv2 (Conv2D  (None, 32, 12, 12)  12832       ['zero_padding2d_5[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3a_pool_bn (BatchNor  (None, 32, 5, 5)    128         ['inception_3a_pool_conv[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_3a_1x1_conv (Conv2D)  (None, 64, 12, 12)  12352       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " inception_3a_3x3_bn2 (BatchNor  (None, 128, 12, 12)  512        ['inception_3a_3x3_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_3a_5x5_bn2 (BatchNor  (None, 32, 12, 12)  128         ['inception_3a_5x5_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 32, 5, 5)     0           ['inception_3a_pool_bn[0][0]']   \n",
            "                                                                                                  \n",
            " inception_3a_1x1_bn (BatchNorm  (None, 64, 12, 12)  256         ['inception_3a_1x1_conv[0][0]']  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 128, 12, 12)  0           ['inception_3a_3x3_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 12, 12)   0           ['inception_3a_5x5_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " zero_padding2d_6 (ZeroPadding2  (None, 32, 12, 12)  0           ['activation_7[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 64, 12, 12)   0           ['inception_3a_1x1_bn[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 256, 12, 12)  0           ['activation_4[0][0]',           \n",
            "                                                                  'activation_6[0][0]',           \n",
            "                                                                  'zero_padding2d_6[0][0]',       \n",
            "                                                                  'activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " inception_3b_3x3_conv1 (Conv2D  (None, 96, 12, 12)  24672       ['concatenate[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3b_5x5_conv1 (Conv2D  (None, 32, 12, 12)  8224        ['concatenate[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3b_3x3_bn1 (BatchNor  (None, 96, 12, 12)  384         ['inception_3b_3x3_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_3b_5x5_bn1 (BatchNor  (None, 32, 12, 12)  128         ['inception_3b_5x5_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 96, 12, 12)   0           ['inception_3b_3x3_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 12, 12)   0           ['inception_3b_5x5_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 256, 4, 4)   0           ['concatenate[0][0]']            \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " zero_padding2d_7 (ZeroPadding2  (None, 96, 14, 14)  0           ['activation_9[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " zero_padding2d_8 (ZeroPadding2  (None, 32, 16, 16)  0           ['activation_11[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " inception_3b_pool_conv (Conv2D  (None, 64, 4, 4)    16448       ['average_pooling2d[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3b_3x3_conv2 (Conv2D  (None, 128, 12, 12)  110720     ['zero_padding2d_7[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3b_5x5_conv2 (Conv2D  (None, 64, 12, 12)  51264       ['zero_padding2d_8[0][0]']       \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3b_pool_bn (BatchNor  (None, 64, 4, 4)    256         ['inception_3b_pool_conv[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_3b_1x1_conv (Conv2D)  (None, 64, 12, 12)  16448       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " inception_3b_3x3_bn2 (BatchNor  (None, 128, 12, 12)  512        ['inception_3b_3x3_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_3b_5x5_bn2 (BatchNor  (None, 64, 12, 12)  256         ['inception_3b_5x5_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 64, 4, 4)     0           ['inception_3b_pool_bn[0][0]']   \n",
            "                                                                                                  \n",
            " inception_3b_1x1_bn (BatchNorm  (None, 64, 12, 12)  256         ['inception_3b_1x1_conv[0][0]']  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 128, 12, 12)  0           ['inception_3b_3x3_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64, 12, 12)   0           ['inception_3b_5x5_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " zero_padding2d_9 (ZeroPadding2  (None, 64, 12, 12)  0           ['activation_13[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 64, 12, 12)   0           ['inception_3b_1x1_bn[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 320, 12, 12)  0           ['activation_10[0][0]',          \n",
            "                                                                  'activation_12[0][0]',          \n",
            "                                                                  'zero_padding2d_9[0][0]',       \n",
            "                                                                  'activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " inception_3c_3x3_conv1 (Conv2D  (None, 128, 12, 12)  41088      ['concatenate_1[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3c_5x5_conv1 (Conv2D  (None, 32, 12, 12)  10272       ['concatenate_1[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3c_3x3_bn1 (BatchNor  (None, 128, 12, 12)  512        ['inception_3c_3x3_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_3c_5x5_bn1 (BatchNor  (None, 32, 12, 12)  128         ['inception_3c_5x5_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 128, 12, 12)  0           ['inception_3c_3x3_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 32, 12, 12)   0           ['inception_3c_5x5_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " zero_padding2d_10 (ZeroPadding  (None, 128, 14, 14)  0          ['activation_15[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " zero_padding2d_11 (ZeroPadding  (None, 32, 16, 16)  0           ['activation_17[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " inception_3c_3x3_conv2 (Conv2D  (None, 256, 6, 6)   295168      ['zero_padding2d_10[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3c_5x5_conv2 (Conv2D  (None, 64, 6, 6)    51264       ['zero_padding2d_11[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_3c_3x3_bn2 (BatchNor  (None, 256, 6, 6)   1024        ['inception_3c_3x3_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_3c_5x5_bn2 (BatchNor  (None, 64, 6, 6)    256         ['inception_3c_5x5_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 320, 5, 5)   0           ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 256, 6, 6)    0           ['inception_3c_3x3_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 64, 6, 6)     0           ['inception_3c_5x5_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " zero_padding2d_12 (ZeroPadding  (None, 320, 6, 6)   0           ['max_pooling2d_3[0][0]']        \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 640, 6, 6)    0           ['activation_16[0][0]',          \n",
            "                                                                  'activation_18[0][0]',          \n",
            "                                                                  'zero_padding2d_12[0][0]']      \n",
            "                                                                                                  \n",
            " inception_4a_3x3_conv1 (Conv2D  (None, 96, 6, 6)    61536       ['concatenate_2[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_4a_5x5_conv1 (Conv2D  (None, 32, 6, 6)    20512       ['concatenate_2[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_4a_3x3_bn1 (BatchNor  (None, 96, 6, 6)    384         ['inception_4a_3x3_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_4a_5x5_bn1 (BatchNor  (None, 32, 6, 6)    128         ['inception_4a_5x5_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 96, 6, 6)     0           ['inception_4a_3x3_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 32, 6, 6)     0           ['inception_4a_5x5_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 640, 2, 2)   0           ['concatenate_2[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " zero_padding2d_13 (ZeroPadding  (None, 96, 8, 8)    0           ['activation_19[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " zero_padding2d_14 (ZeroPadding  (None, 32, 10, 10)  0           ['activation_21[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " inception_4a_pool_conv (Conv2D  (None, 128, 2, 2)   82048       ['average_pooling2d_1[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_4a_3x3_conv2 (Conv2D  (None, 192, 6, 6)   166080      ['zero_padding2d_13[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_4a_5x5_conv2 (Conv2D  (None, 64, 6, 6)    51264       ['zero_padding2d_14[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_4a_pool_bn (BatchNor  (None, 128, 2, 2)   512         ['inception_4a_pool_conv[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_4a_1x1_conv (Conv2D)  (None, 256, 6, 6)   164096      ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " inception_4a_3x3_bn2 (BatchNor  (None, 192, 6, 6)   768         ['inception_4a_3x3_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_4a_5x5_bn2 (BatchNor  (None, 64, 6, 6)    256         ['inception_4a_5x5_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 128, 2, 2)    0           ['inception_4a_pool_bn[0][0]']   \n",
            "                                                                                                  \n",
            " inception_4a_1x1_bn (BatchNorm  (None, 256, 6, 6)   1024        ['inception_4a_1x1_conv[0][0]']  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 192, 6, 6)    0           ['inception_4a_3x3_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 64, 6, 6)     0           ['inception_4a_5x5_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " zero_padding2d_15 (ZeroPadding  (None, 128, 6, 6)   0           ['activation_23[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 256, 6, 6)    0           ['inception_4a_1x1_bn[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 640, 6, 6)    0           ['activation_20[0][0]',          \n",
            "                                                                  'activation_22[0][0]',          \n",
            "                                                                  'zero_padding2d_15[0][0]',      \n",
            "                                                                  'activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " inception_4e_3x3_conv1 (Conv2D  (None, 160, 6, 6)   102560      ['concatenate_3[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_4e_5x5_conv1 (Conv2D  (None, 64, 6, 6)    41024       ['concatenate_3[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_4e_3x3_bn1 (BatchNor  (None, 160, 6, 6)   640         ['inception_4e_3x3_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_4e_5x5_bn1 (BatchNor  (None, 64, 6, 6)    256         ['inception_4e_5x5_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 160, 6, 6)    0           ['inception_4e_3x3_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 64, 6, 6)     0           ['inception_4e_5x5_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " zero_padding2d_16 (ZeroPadding  (None, 160, 8, 8)   0           ['activation_25[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " zero_padding2d_17 (ZeroPadding  (None, 64, 10, 10)  0           ['activation_27[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " inception_4e_3x3_conv2 (Conv2D  (None, 256, 3, 3)   368896      ['zero_padding2d_16[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_4e_5x5_conv2 (Conv2D  (None, 128, 3, 3)   204928      ['zero_padding2d_17[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_4e_3x3_bn2 (BatchNor  (None, 256, 3, 3)   1024        ['inception_4e_3x3_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_4e_5x5_bn2 (BatchNor  (None, 128, 3, 3)   512         ['inception_4e_5x5_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, 640, 2, 2)   0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 256, 3, 3)    0           ['inception_4e_3x3_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 128, 3, 3)    0           ['inception_4e_5x5_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " zero_padding2d_18 (ZeroPadding  (None, 640, 3, 3)   0           ['max_pooling2d_4[0][0]']        \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 1024, 3, 3)   0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_28[0][0]',          \n",
            "                                                                  'zero_padding2d_18[0][0]']      \n",
            "                                                                                                  \n",
            " inception_5a_3x3_conv1 (Conv2D  (None, 96, 3, 3)    98400       ['concatenate_4[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_5a_3x3_bn1 (BatchNor  (None, 96, 3, 3)    384         ['inception_5a_3x3_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 96, 3, 3)     0           ['inception_5a_3x3_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 1024, 1, 1)  0           ['concatenate_4[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " zero_padding2d_19 (ZeroPadding  (None, 96, 5, 5)    0           ['activation_29[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " inception_5a_pool_conv (Conv2D  (None, 96, 1, 1)    98400       ['average_pooling2d_2[0][0]']    \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_5a_3x3_conv2 (Conv2D  (None, 384, 3, 3)   332160      ['zero_padding2d_19[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_5a_pool_bn (BatchNor  (None, 96, 1, 1)    384         ['inception_5a_pool_conv[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_5a_1x1_conv (Conv2D)  (None, 256, 3, 3)   262400      ['concatenate_4[0][0]']          \n",
            "                                                                                                  \n",
            " inception_5a_3x3_bn2 (BatchNor  (None, 384, 3, 3)   1536        ['inception_5a_3x3_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 96, 1, 1)     0           ['inception_5a_pool_bn[0][0]']   \n",
            "                                                                                                  \n",
            " inception_5a_1x1_bn (BatchNorm  (None, 256, 3, 3)   1024        ['inception_5a_1x1_conv[0][0]']  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 384, 3, 3)    0           ['inception_5a_3x3_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " zero_padding2d_20 (ZeroPadding  (None, 96, 3, 3)    0           ['activation_31[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 256, 3, 3)    0           ['inception_5a_1x1_bn[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate)    (None, 736, 3, 3)    0           ['activation_30[0][0]',          \n",
            "                                                                  'zero_padding2d_20[0][0]',      \n",
            "                                                                  'activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " inception_5b_3x3_conv1 (Conv2D  (None, 96, 3, 3)    70752       ['concatenate_5[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_5b_3x3_bn1 (BatchNor  (None, 96, 3, 3)    384         ['inception_5b_3x3_conv1[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 96, 3, 3)     0           ['inception_5b_3x3_bn1[0][0]']   \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 736, 1, 1)   0           ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " zero_padding2d_21 (ZeroPadding  (None, 96, 5, 5)    0           ['activation_33[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " inception_5b_pool_conv (Conv2D  (None, 96, 1, 1)    70752       ['max_pooling2d_5[0][0]']        \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_5b_3x3_conv2 (Conv2D  (None, 384, 3, 3)   332160      ['zero_padding2d_21[0][0]']      \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inception_5b_pool_bn (BatchNor  (None, 96, 1, 1)    384         ['inception_5b_pool_conv[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " inception_5b_1x1_conv (Conv2D)  (None, 256, 3, 3)   188672      ['concatenate_5[0][0]']          \n",
            "                                                                                                  \n",
            " inception_5b_3x3_bn2 (BatchNor  (None, 384, 3, 3)   1536        ['inception_5b_3x3_conv2[0][0]'] \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 96, 1, 1)     0           ['inception_5b_pool_bn[0][0]']   \n",
            "                                                                                                  \n",
            " inception_5b_1x1_bn (BatchNorm  (None, 256, 3, 3)   1024        ['inception_5b_1x1_conv[0][0]']  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 384, 3, 3)    0           ['inception_5b_3x3_bn2[0][0]']   \n",
            "                                                                                                  \n",
            " zero_padding2d_22 (ZeroPadding  (None, 96, 3, 3)    0           ['activation_35[0][0]']          \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 256, 3, 3)    0           ['inception_5b_1x1_bn[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 736, 3, 3)    0           ['activation_34[0][0]',          \n",
            "                                                                  'zero_padding2d_22[0][0]',      \n",
            "                                                                  'activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 736, 1, 1)   0           ['concatenate_6[0][0]']          \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 736)          0           ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " dense_layer (Dense)            (None, 128)          94336       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 128)          0           ['dense_layer[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,743,280\n",
            "Trainable params: 3,733,968\n",
            "Non-trainable params: 9,312\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "FRmodel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(FRmodel, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-hODDd9-iZC"
      },
      "source": [
        "## 4 - Aplicando el modelo\n",
        "\n",
        "### 4.1 - Face Verification\n",
        "\n",
        "Construyamos una base de datos que contenga un vector de codificación para cada persona a la que se le permite ingresar a la oficina. Para generar la codificación usamos `img_to_encoding(image_path, model)`, que ejecuta el forward propagation del modelo en la imagen especificada.\n",
        "\n",
        "Ejecute el siguiente código para construir la base de datos (representada como un diccionario de python). Esta base de datos asigna el nombre de cada persona a una codificación de 128 dimensiones de su rostro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP1Jw2PP-iZD",
        "outputId": "dca6fc78-48ff-4bfd-fd2e-cbe79b24fc98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        }
      ],
      "source": [
        "database = {}\n",
        "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", FRmodel)\n",
        "database[\"younes\"] = img_to_encoding(\"images/younes.jpg\", FRmodel)\n",
        "database[\"tian\"] = img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
        "database[\"andrew\"] = img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
        "database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
        "database[\"dan\"] = img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
        "database[\"sebastiano\"] = img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
        "database[\"bertrand\"] = img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
        "database[\"kevin\"] = img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
        "database[\"felix\"] = img_to_encoding(\"images/felix.jpg\", FRmodel)\n",
        "database[\"benoit\"] = img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
        "database[\"arnaud\"] = img_to_encoding(\"images/arnaud.jpg\", FRmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eDMrb_M-iZE"
      },
      "source": [
        "Ahora, cuando alguien aparece en la puerta y desliza su tarjeta de identificación (y así le da su nombre), puede buscar su codificación en la base de datos y usarla para verificar si la persona que está parada en la puerta de entrada coincide con el nombre en la identificación.\n",
        "\n",
        "**Implemente** verify() que verifica si la imagen de la cámara de la puerta principal (`image_path`) es realmente la persona llamada \"identity\". Tendrás que seguir los siguientes pasos:\n",
        "1. Calcule la codificación de la imagen desde `image_path`.\n",
        "2. Calcular la distancia entre esta codificación y la codificación de la imagen identity almacenada en la base de datos.\n",
        "3. Abra la puerta si la distancia es inferior a 0.7; de lo contrario, no la abra.\n",
        "\n",
        "* Como se presentó anteriormente, debe usar la distancia L2 [np.linalg.norm](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "shQp3-Ur-iZE"
      },
      "outputs": [],
      "source": [
        "def verify(image_path, identity, database, model):\n",
        "    \"\"\"\n",
        "     Función que verifica si la persona en la imagen \"image_path\" es \"identity\".\n",
        "    \n",
        "     Argumentos:\n",
        "     image_path -- ruta a una imagen\n",
        "     identity: string, nombre de la persona cuya identidad desea verificar. Tiene que ser un empleado que trabaja en la oficina.\n",
        "     database: el diccionario de python asigna nombres de personas permitidas (strings) a sus codificaciones (vectores).\n",
        "     model: su instancia de modelo Inception en Keras\n",
        "    \n",
        "     Devoluciones:\n",
        "     dist: distancia entre image_path y la imagen de \"identity\" en la base de datos.\n",
        "     door_open -- True, si la puerta debe abrirse. False en caso contrario.\n",
        "     \"\"\"\n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "    dist = np.linalg.norm(encoding - database[identity])\n",
        "\n",
        "    if dist < 0.7:\n",
        "        print(\"Usted \" + str(identity) + \", welcome in!\")\n",
        "        door_open = True\n",
        "    else:\n",
        "        print(\"Usted no es \" + str(identity) + \", por favor siga adelante\")\n",
        "        door_open = False\n",
        "\n",
        "    return dist, door_open\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrZvcjyx-iZE"
      },
      "source": [
        "Younes está tratando de entrar a la oficina y la cámara le toma una foto (\"images/camera_0.jpg\"). Ejecutemos su algoritmo de verificación en esta imagen:\n",
        "\n",
        "<img src=\"images/camera_0.jpg\" style=\"width:100px;height:100px;\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0kOOy_s-iZE",
        "outputId": "a68d50ee-eb19-473a-f947-c31f771a011b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "Usted younes, welcome in!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.66713977, True)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "verify(\"images/camera_0.jpg\", \"younes\", database, FRmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwrVPzHl-iZE"
      },
      "source": [
        "Benoit, que no trabaja en la oficina, robó la tarjeta de identificación de Kian e intentó ingresar a la oficina. La cámara tomó una foto de Benoit (\"images/camera_2.jpg). Ejecutemos el algoritmo de verificación para verificar si benoit puede ingresar.\n",
        "\n",
        "<img src=\"images/camera_2.jpg\" style=\"width:100px;height:100px;\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEFspdi2-iZF",
        "outputId": "774596c0-8a02-4e16-8a40-38f4f608a5e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Usted no es kian, por favor siga adelante\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.85868865, False)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "verify(\"images/camera_2.jpg\", \"kian\", database, FRmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkhsw2j6-iZF"
      },
      "source": [
        "### 4.2 - Face Recognition\n",
        "\n",
        "Su sistema de verificación facial funciona bien en su mayoría. Pero como a Kian le robaron su tarjeta de identificación, cuando regresó a la oficina al día siguiente ¡no pudo entrar!\n",
        "\n",
        "Para resolver esto, le gustaría cambiar su sistema de verificación facial a un sistema de reconocimiento facial. De esta manera, ya nadie tiene que llevar una tarjeta de identificación. ¡Una persona autorizada puede caminar hasta el edificio y la puerta se desbloqueará para ellos!\n",
        "\n",
        "Implementará un sistema de reconocimiento facial que toma como entrada una imagen y determina si es una de las personas autorizadas (y, de ser así, quién). A diferencia del sistema de verificación facial anterior, ya no obtendremos el nombre de una persona como una de las entradas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVuRLV7l-iZF"
      },
      "source": [
        "**Implementar** `who_is_it()`. Tendrás que seguir los siguientes pasos:\n",
        "1. Calcule la codificación de destino de la imagen de image_path\n",
        "2. Encuentre la codificación de la base de datos que tiene la distancia más pequeña con la codificación de destino.\n",
        "     - Inicializar la variable `min_dist` a un número lo suficientemente grande (100). Le ayudará a realizar un seguimiento de cuál es la codificación más cercana a la codificación de la entrada.\n",
        "     - Bucle sobre los nombres y codificaciones del diccionario de la base de datos. Para hacer un bucle, use `for (name, db_enc) en base de datos.items()`.\n",
        "         - Calcule la distancia L2 entre la \"codificación\" de destino y la \"codificación\" actual de la base de datos.\n",
        "         - Si esta distancia es menor que min_dist, establezca `min_dist` en `dist` e `identity` en `name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ke3f-6WY-iZF"
      },
      "outputs": [],
      "source": [
        "def who_is_it(image_path, database, model):\n",
        "    \"\"\"\n",
        "     Implementa el reconocimiento facial para la oficina al encontrar quién es la persona en la imagen image_path.\n",
        "    \n",
        "     Argumentos:\n",
        "     image_path -- ruta a una imagen\n",
        "     database: base de datos que contiene codificaciones de imágenes junto con el nombre de la persona en la imagen\n",
        "     model: su instancia de modelo Inception en Keras\n",
        "    \n",
        "     Devoluciones:\n",
        "     min_dist: la distancia mínima entre la codificación image_path y las codificaciones de la base de datos\n",
        "     identity-- string, la predicción de nombre para la persona en image_path\n",
        "     \"\"\"\n",
        "\n",
        "    encoding = img_to_encoding(image_path, model)\n",
        "    # Inicializar \"min_dist\" a un valor grande, digamos 100\n",
        "    min_dist = 100\n",
        "    # Recorre los nombres y codificaciones del diccionario de la base de datos.\n",
        "    for (name, db_enc) in database.items():\n",
        "        dist = np.linalg.norm(encoding-db_enc)\n",
        "        # Si esta distancia es menor que min_dist, establezca min_dist en dist e identidad en name. (≈ 3 líneas)\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            identity = name\n",
        "\n",
        "    if min_dist > 0.7:\n",
        "            print('No está en la base de datos')\n",
        "    else:\n",
        "            print(\"Está \" + str(identity) + \", la distancia es \" + str(min_dist))\n",
        "            \n",
        "    return min_dist, identity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vyj_z-u-iZG"
      },
      "source": [
        "Younes está en la puerta principal y la cámara le toma una foto (\"images/camera_0.jpg\"). Veamos si su algoritmo who_it_is() identifica a Younes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1dq0uPT-iZG",
        "outputId": "3718a834-2740-44c0-9a4e-ab6134bce8f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "Está younes, la distancia es 0.66713977\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.66713977, 'younes')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "who_is_it(\"images/camera_0.jpg\", database, FRmodel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlKSQZtR-iZG"
      },
      "source": [
        "#### Formas de mejorar su modelo de reconocimiento facial\n",
        "Aunque no lo implementaremos aquí, aquí hay algunas formas de mejorar aún más el algoritmo:\n",
        "- Poner más imágenes de cada persona (en diferentes condiciones de iluminación, tomadas en diferentes días, etc.) en la base de datos. Luego, dada una nueva imagen, compare la nueva cara con varias imágenes de la persona. Esto aumentaría la precisión.\n",
        "- Recorte las imágenes para que solo contengan la cara y menos la región del \"borde\" alrededor de la cara. Este preprocesamiento elimina algunos de los píxeles irrelevantes alrededor de la cara y también hace que el algoritmo sea más robusto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffxj7Iwe-iZG"
      },
      "source": [
        "## Puntos clave para recordar\n",
        "- La verificación facial resuelve un problema de coincidencia 1:1 más fácil; el reconocimiento facial aborda un problema de coincidencia 1:K más difícil.\n",
        "- La pérdida de triplete es una función de pérdida efectiva para entrenar una red neuronal para aprender una codificación de una imagen de rostro.\n",
        "- La misma codificación se puede utilizar para la verificación y el reconocimiento. Medir las distancias entre las codificaciones de dos imágenes le permite determinar si son fotografías de la misma persona."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3EyiE4S-iZG"
      },
      "source": [
        "#### Referencias\n",
        "\n",
        "- Florian Schroff, Dmitry Kalenichenko, James Philbin (2015). [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf)\n",
        "- Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, Lior Wolf (2014). [DeepFace: Closing the gap to human-level performance in face verification](https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf) \n",
        "- The pretrained model we use is inspired by Victor Sy Wang's implementation and was loaded using his code: https://github.com/iwantooxxoox/Keras-OpenFace.\n",
        "- Our implementation also took a lot of inspiration from the official FaceNet github repository: https://github.com/davidsandberg/facenet "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.8 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4edecc0c6a4f0e1e3de79ca77741107a175241f6f71b1c161b36dd6ac31a9479"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
